{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uLWOaI8GOW8z"
      },
      "source": [
        "#Imports and Installations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AawPXH2kOB8F"
      },
      "outputs": [],
      "source": [
        "# imports\n",
        "from google.colab import files\n",
        "\n",
        "import io\n",
        "import wave\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.io.wavfile as wavfile\n",
        "import IPython.display as ipd\n",
        "from IPython.display import display, Audio\n",
        "\n",
        "from scipy.fft import fft, fftfreq\n",
        "from scipy.io import wavfile\n",
        "from scipy import signal\n",
        "from scipy.signal import resample\n",
        "from scipy.signal import find_peaks\n",
        "import scipy.signal as signal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pI0rg07SOVmu",
        "outputId": "2f7724e3-e217-4591-e7e5-da2ad834a386"
      },
      "outputs": [],
      "source": [
        "# installations\n",
        "\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "!apt-get install -y portaudio19-dev\n",
        "!pip install sounddevice\n",
        "import sounddevice as sd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBmr7OShObJy"
      },
      "source": [
        "## Plotting and playing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97-NVGKoOfXp"
      },
      "outputs": [],
      "source": [
        "# Plot time series\n",
        "def plotTime(data, fs, title):\n",
        "\n",
        "  time = np.arange(len(data)) / fs\n",
        "\n",
        "  plt.figure(figsize=(10, 4))\n",
        "\n",
        "  plt.plot(time, data, color='black')\n",
        "  plt.xlabel('Time (seconds)') # label the x-axis\n",
        "  plt.ylabel('Amplitude') # label the y-axis\n",
        "  plt.title(title) # label the title of the plot\n",
        "  plt.grid(True) # enable grid on the plot\n",
        "  plt.show()\n",
        "\n",
        "# Plot fft\n",
        "def plotFFT(data, fs, title):\n",
        "\n",
        "  data_fft = np.fft.fft(data)\n",
        "  freq = np.fft.fftfreq(len(data), 1/fs)\n",
        "\n",
        "  plt.plot(freq, np.abs(data_fft), color='black')\n",
        "  plt.xlabel('Frequency (Hz)')\n",
        "  plt.ylabel('Amplitude')\n",
        "  plt.title(title)\n",
        "  plt.xlim(left=0)\n",
        "  plt.grid(True) # enable grid on the plot\n",
        "  plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XJHciqZTQzJM"
      },
      "outputs": [],
      "source": [
        "# Plays audio\n",
        "\n",
        "def play_audio(audio, sample_rate=16000, filename='new_audio.wav'):\n",
        "\n",
        "    # Save the combined audio as a WAV file in Google Colab\n",
        "    wavfile.write('/content/audio.wav', sample_rate, audio.astype(np.int16))\n",
        "\n",
        "    # Play the saved WAV file using the URL parameter of IPython.display.Audio\n",
        "    audio_url = '/content/audio.wav'\n",
        "    return display(Audio(audio_url))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y4Y_fEbsQMiv"
      },
      "source": [
        "#Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHRKhj4EQPXo"
      },
      "outputs": [],
      "source": [
        "#Downsample data to 16000 Hz\n",
        "\n",
        "def downsample_16000(data, fs):\n",
        "\n",
        "      # Downsampling factor\n",
        "      resampling_ratio = fs / 16000\n",
        "\n",
        "      # Downsample the data using scipy.signal.resample\n",
        "      downsampled_data = resample(data, int(len(data) / resampling_ratio))\n",
        "\n",
        "      # Save the downsampled data to a new WAV file\n",
        "      wavfile.write('input_file_16000Hz.wav', 16000, downsampled_data.astype(data.dtype))\n",
        "      input_wav_file = 'input_file_16000Hz.wav'\n",
        "      fs,data = wavfile.read(input_wav_file) #loads the file and its sampling frequency\n",
        "\n",
        "      return fs,data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7MkTbQlrQS3o"
      },
      "source": [
        "#Time Segmentation Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "89JXoax6QWph"
      },
      "outputs": [],
      "source": [
        "#Time segmentation using retangular or Hanning window\n",
        "def segmentation(audio_file, segment_ms, overlap_ratio, gap_ms, isHanning):\n",
        "\n",
        "    #Converting variables to data points\n",
        "    segment_length = int(sr * segment_ms / 1000)\n",
        "    overlap_length = int(segment_length * overlap_ratio)\n",
        "    gap_length     = int(sr * gap_ms / 1000)\n",
        "\n",
        "    segments = []\n",
        "    start_index = 0\n",
        "\n",
        "    while start_index + segment_length <= len(audio_file):\n",
        "        segment = audio_file[start_index : start_index + segment_length]\n",
        "        segments.append(segment)\n",
        "\n",
        "        if overlap_length > 0:\n",
        "            start_index += segment_length - overlap_length\n",
        "\n",
        "        elif gap_length > 0:\n",
        "            start_index += segment_length + abs(gap_length)\n",
        "\n",
        "        else:\n",
        "            start_index += segment_length\n",
        "\n",
        "    if isHanning == True:\n",
        "        hanning_window = np.hanning(segment_length)\n",
        "        segments = segments * hanning_window\n",
        "\n",
        "    return segments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v6P1yhyIQljb"
      },
      "outputs": [],
      "source": [
        "#Concatenate segmented data\n",
        "def concatenate_segments(segments, segment_ms, sr, overlap_ratio, gap_ms):\n",
        "\n",
        "    segments = np.array(segments)\n",
        "\n",
        "    #Converting variables to data points\n",
        "    segment_length = int(sr * segment_ms / 1000)\n",
        "    overlap_length = int(segment_length * overlap_ratio)\n",
        "    gap_length     = int(sr * gap_ms / 1000)\n",
        "    num_segments   = segments.shape[0]\n",
        "\n",
        "    #Concatenate segments into one array\n",
        "    if overlap_length == 0 and gap_length == 0: #If no overlap or gap\n",
        "        data = np.concatenate(segments)\n",
        "\n",
        "    elif overlap_length > 0: #If overlap\n",
        "        data = segments[0]\n",
        "\n",
        "        for segment in segments[1:]:\n",
        "            overlap = data[-overlap_length:]\n",
        "            data = data[:-overlap_length]\n",
        "            new_segment = segment[:overlap_length] + overlap\n",
        "\n",
        "            data = np.concatenate((data, new_segment))\n",
        "            data = np.concatenate((data, segment[overlap_length:]))\n",
        "\n",
        "    elif gap_length > 0: #If gap\n",
        "        gap = np.zeros(gap_length)\n",
        "\n",
        "        for segment in segments:\n",
        "            segment = np.concatenate(gap)\n",
        "\n",
        "            data = np.concatenate(segment)\n",
        "\n",
        "    return data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCXuh8SAQbTG"
      },
      "source": [
        "#Frequency Domain Analysis Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QRbvpbzQe2e"
      },
      "outputs": [],
      "source": [
        "def find_dominant_frequencies(segment, fs, amp_height):\n",
        "    n = len(segment)\n",
        "    # fft_result = fft(segments_fft)\n",
        "    segment_fft = np.fft.fft(segment)\n",
        "    fft_magnitude = np.abs(segment_fft)\n",
        "    frequencies = np.fft.fftfreq(n, d=1/fs)\n",
        "\n",
        "    # Ignore the negative frequencies and corresponding magnitudes\n",
        "    positive_frequencies = frequencies[:n // 2]\n",
        "    positive_magnitudes = fft_magnitude[:n // 2]\n",
        "\n",
        "    # Find peaks in the FFT magnitude spectrum\n",
        "    peaks, _ = find_peaks(positive_magnitudes, height=amp_height)  # Adjust the threshold as needed\n",
        "\n",
        "    dominant_frequencies = positive_frequencies[peaks]\n",
        "    dominant_magnitudes = positive_magnitudes[peaks]\n",
        "\n",
        "    return dominant_frequencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q0h1KdtJ28w5"
      },
      "outputs": [],
      "source": [
        "def synthesize(hanning_segments, sr, amp_height, width, filter_order):\n",
        "\n",
        "    final_audio = [] #Initialize array to hold final segments\n",
        "    num_dom_freq = [] #Initialize number of dominant frequncies per segment\n",
        "\n",
        "    #Iterate through segments\n",
        "    for i, segment in enumerate(hanning_segments):\n",
        "\n",
        "        synth_segment = np.zeros(len(segment)) #array to hold superimposed synthesized rms for a single segment\n",
        "\n",
        "        start_idx = i * len(segment) #assuming no overlap or gap\n",
        "        time = (np.arange(len(segment)) + start_idx) / sr # time array for a given segment\n",
        "\n",
        "        #Find dominant frequencies for current segment\n",
        "        dominant_frequencies = find_dominant_frequencies(segment, sr, amp_height)\n",
        "\n",
        "        if len(dominant_frequencies) > 0: #If there are dominante frequencies\n",
        "\n",
        "            num_dom_freq.append(len(dominant_frequencies))\n",
        "\n",
        "            for freq in dominant_frequencies: #Iterate through dominant frequencies\n",
        "                synth = [] #array to hold syntesized segement for single frequency\n",
        "\n",
        "                filtered_segment = apply_bandpass_filter(segment, sr, freq, width, filter_order) #Apply single bandpass filter to segment\n",
        "                rms = np.sqrt(np.mean(filtered_segment ** 2)) #Apply rms to single bandpass filter segment\n",
        "\n",
        "                # Syntesize a single frequency within a single segment\n",
        "                for t in time:\n",
        "                    synth.append(rms * np.sin(2 * np.pi * freq * t))\n",
        "\n",
        "                # Superimpose the synthesized frequencies for this segment\n",
        "                synth_segment += np.array(synth)\n",
        "\n",
        "        final_audio.append(synth_segment)\n",
        "\n",
        "    #Get the avergae number of dominant frequencies per segment\n",
        "    print('Average number of Dominant Frequencies: ' + str(np.mean(num_dom_freq)))\n",
        "\n",
        "    return final_audio\n",
        "\n",
        "\n",
        "def apply_bandpass_filter(segment, fs, center_freq, width, filter_order):\n",
        "    nyquist = 0.5 * fs\n",
        "    low_cutoff = center_freq - width / 2\n",
        "    high_cutoff = center_freq + width / 2\n",
        "\n",
        "    # Create band-pass filter\n",
        "    sos_BP = signal.butter(N=filter_order, Wn=[low_cutoff/nyquist, high_cutoff/nyquist], btype='bandpass', output='sos')\n",
        "\n",
        "    # Apply the filter to the segment\n",
        "    filtered_segment = signal.sosfilt(sos_BP, segment)\n",
        "\n",
        "    return filtered_segment\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEJ2rsW3Q4Tn"
      },
      "source": [
        "#Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "zBQsEO0yQ3lr",
        "outputId": "e202c3ec-d41d-4637-cc45-d5aa5bab5cb8"
      },
      "outputs": [],
      "source": [
        "#Importing and downsampling audio file\n",
        "audio_file = '/input.wav'\n",
        "\n",
        "sr, audio = wavfile.read(audio_file)\n",
        "print(\"Original ampling frequency: \" + str(sr)) #get original sample rate\n",
        "\n",
        "if sr > 16000:\n",
        "  sr, data = downsample_16000(audio, sr)\n",
        "  print(\"Downsampled frequency: \" + str(sr)) #get downsampled sample rate\n",
        "\n",
        "#Plotting original time series of audio file\n",
        "plotTime(data, sr, \"Original Time Series\")\n",
        "\n",
        "#Play original downsampled audio\n",
        "play_audio(data, sample_rate=16000, filename='new_audio.wav')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jVMfjoVaSMhe",
        "outputId": "8a84ba45-0d88-4964-faf5-8f63c1d3c689"
      },
      "outputs": [],
      "source": [
        "#Segmenting data into equal sized 'chunks'\n",
        "\n",
        "#Segmenting variables\n",
        "chunk_ms      = 20    # Length of chunk in milliseconds\n",
        "overlap_ratio = 0.5   # Ratio of chunk that is overlaped by its neighbouring chunks\n",
        "gap_ms        = 0     # Length of gap in milliseconds\n",
        "isHanning     = True  # If False: rectangual window is applied\n",
        "                      # If True: Hanning window is applied\n",
        "\n",
        "#Segmenting data into equal sized 'chunks' using a hanning window\n",
        "segments = segmentation(data, chunk_ms, overlap_ratio, gap_ms, isHanning)\n",
        "\n",
        "#Print Number of chunks\n",
        "segments = np.array(segments)\n",
        "print('Number of chunks: '+ str(segments.shape[0]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "40dUbwEM17qM",
        "outputId": "df3812f7-5233-4484-87d2-4e1cb0165ab7"
      },
      "outputs": [],
      "source": [
        "#Apply series of bandpass filters and synthesize segments\n",
        "\n",
        "#Filtering variables\n",
        "amplitude_height = 5000   # Threshold for finding dominant frequencies\n",
        "bandwidth        = 10     # Bandwidth of the band-pass filter\n",
        "filter_order     = 1      # Order of butterworth bandpass filter\n",
        "\n",
        "#Synthesize audio\n",
        "synthesized_audio = synthesize(segments, sr, amplitude_height, bandwidth, filter_order)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "id": "GMNOKDoG5f21",
        "outputId": "115876cc-0bba-410a-99dd-5f1b9ed2bc7e"
      },
      "outputs": [],
      "source": [
        "#Concatenate segments, plot in time domain and play audio #30\n",
        "\n",
        "concat_audio = concatenate_segments(synthesized_audio, chunk_ms, sr, overlap_ratio, gap_ms)\n",
        "plotTime(concat_audio, sr, \"Synthesized Time Sream\")\n",
        "play_audio(concat_audio, sample_rate=16000, filename='new_audio.wav')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
